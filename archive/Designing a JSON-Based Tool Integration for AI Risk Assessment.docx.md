# Designing a JSON-Based Tool Integration for AI Risk Assessment

## Unified JSON Input/Output Structure

Using a **single JSON file for both input and output** simplifies the workflow for both AI agents and human auditors. By consolidating data into one JSON structure, you avoid juggling multiple files or formats during the risk assessment process. This unified JSON can encapsulate all necessary information (e.g. identified risks, context, preliminary AI analysis) as input, and carry the updated or annotated data as output after the auditor’s review. Adopting one JSON schema makes manual operations straightforward – an auditor can **upload one file and download one file** – reducing complexity and potential user error. From a technical standpoint, defining a clear JSON schema for this file is important so that both the AI agent and the tool know exactly what fields to expect. In fact, best practices in secure AI tool design recommend enforcing strict JSON schema validation on inputs and rejecting unexpected fields[\[1\]](https://cyberstrategyinstitute.com/ai-safe%C2%B2-a-next-generation-secure-ai-agent-framework-for-agentic-ai-automation/#:~:text=2), ensuring the data structure remains consistent and safe. Moreover, under emerging standards like Anthropic’s *Model Context Protocol (MCP)*, each external tool is defined by a specific input schema and output schema for JSON-based communication[\[2\]](https://zenity.io/blog/security/securing-the-model-context-protocol-mcp#:~:text=Functional%20units%20that%20the%20model,Each%20tool%20has). Designing your risk assessment interface around a single well-defined JSON aligns with these standards, making it easier to integrate the tool with AI agents while keeping it user-friendly for manual use.

## Flow 1: AI Agent-Integrated Usage (Automatic)

In the first scenario, an **AI agent directly interfaces with the risk assessment tool** using the unified JSON. This typically happens via an API or MCP connection, allowing the AI to send data and receive results in JSON format without human intervention in the data transfer. The process would work as follows:

1. **AI Prepares JSON Input:** The AI agent gathers the necessary risk data (perhaps by analyzing documents or prior discussions) and compiles it into the structured JSON input. This JSON might include fields such as risk items, descriptions, initial risk scores or categories suggested by the AI, etc.

2. **AI Calls the Tool (MCP Invocation):** The agent invokes the risk assessment tool by sending this JSON input. Through the **Model Context Protocol (MCP)** or a similar mechanism, the tool is called as a “function” with the JSON data as its parameter. (MCP is essentially an open standard RPC that lets AI agents dynamically invoke external tools via JSON requests[\[3\]](https://zenity.io/blog/security/securing-the-model-context-protocol-mcp#:~:text=In%202025%2C%20the%20rise%20of,tools%2C%20APIs%2C%20databases%2C%20and%20services)[\[4\]](https://zenity.io/blog/security/securing-the-model-context-protocol-mcp#:~:text=MCP%20is%20an%20open%2C%20composable,LLMs%29%20to).)

3. **User Reviews via Tool UI:** The tool opens its **visual interface** (e.g. a web UI or app screen) for the auditor with the data pre-loaded. At this stage, the auditor – a human in the loop – can see the AI-populated risk assessment data and make any needed edits or additions. For example, the auditor might adjust risk ratings, correct any context misunderstandings, or add commentary. The AI agent effectively “pauses” while the auditor is reviewing. This design keeps the human auditor firmly in control of final judgments, reflecting a human-in-the-loop approach recommended in AI governance (i.e. AI provides a draft, but humans validate or override before proceeding)[\[5\]](https://www.wolterskluwer.com/en/expert-insights/revolutionary-impact-ai-powered-risk-assessment-internal-audit#:~:text=Implement%20a%20human).

4. **Completion and JSON Output Return:** Once the auditor is satisfied, they indicate completion (e.g. clicking a finalize button). The tool then generates the **output JSON**, which includes all updates the auditor made. This JSON is returned back to the AI agent through the integration channel. Because the tool is using a single JSON format, the agent can easily ingest this updated data and continue the risk assessment workflow.

5. **AI Resumes with Updated Data:** The AI agent now continues its process (e.g. generating a final risk report or making recommendations) using the human-verified data from the JSON output. The cycle may repeat if further review steps are needed, but the key is that the *data transfer was seamless*: one JSON in, one JSON out.

**Technical considerations:** In this automated flow, the AI agent’s environment must support calling the tool and awaiting the user’s input. Some advanced AI agent platforms and IDEs allow this by treating the tool as an interactive step. For instance, an AI “copilot” could open a web UI for the tool and suspend its own output until it receives the completed JSON. Because the data is not stored on any backend and is only passed through the tool, the privacy of sensitive risk information is maintained – it lives briefly in memory or the front-end during editing, then returns to the AI agent. No persistent copies remain on the tool’s server, honoring the requirement that *the data is never permanently stored by the tool*. This approach mitigates data retention risks (e.g. nothing sensitive remains on the tool after use) and avoids complications with privacy regulations.

## Flow 2: Manual Auditor Workflow (No Direct Agent Connection)

The second scenario addresses cases where the **auditor uses the tool manually**, without an automated agent connection. This might be because the auditor prefers a hands-on approach or the environment doesn’t support direct integration. The workflow in this case is slightly different but leverages the same JSON format:

1. **AI Provides JSON to Auditor:** The auditor first asks the AI agent to prepare the input JSON. The AI agent will output the structured JSON (for example, the agent might present it as a file download or as text the user can copy). This JSON contains the AI’s compiled assessment data just like in flow 1\.

2. **Auditor Uploads JSON to Tool:** The auditor then goes to the risk assessment tool’s interface (e.g. a web page) and **uploads the JSON file**. Because the tool is designed around a single JSON input, the user just has to deal with one file. The tool reads this JSON and populates the interface with the data (risk items, preliminary assessments, etc.).

3. **User Edits in Tool UI:** The auditor uses the tool’s visual interface to review and modify the risk data. They might correct any errors, adjust risk levels, or input additional context that the AI might have missed. The tool could provide a rich UI to make this easy – for example, form fields, sliders for risk scores, or tables. (This is analogous to filling out a form but pre-filled by AI suggestions.)

4. **Download Updated JSON:** After making the edits, the auditor clicks a button to **export or download** the updated JSON output. The tool generates a JSON file that now reflects the auditor’s changes. Since the design uses the same unified JSON structure, the output file is essentially the input JSON with modifications (and possibly new fields like an “approved” flag or auditor notes added).

5. **Provide JSON Back to AI:** Finally, the auditor returns this JSON to the AI agent. This could be done by uploading the file into the AI agent’s chat or interface, or by copy-pasting the JSON content if needed. The AI agent then parses the updated JSON and continues the risk assessment process with the auditor-approved data.

This manual flow ensures that even if there’s **no automatic integration**, the process remains user-friendly. The auditor doesn’t have to coordinate multiple files or complex steps – just upload, edit, download. It’s effectively the same as the automatic flow, but with the user doing the send/receive steps manually. The consistency of one JSON format means the AI’s output and the tool’s input/output are in harmony, avoiding any data translation issues.

*Example: A modern audit interface combining AI assistance with human oversight. In the Wolters Kluwer TeamMate+ platform, an “AI Editor” suggests content to auditors but the human reviewer controls the final output. Similarly, our tool allows the AI to provide input, yet the auditor reviews and edits that input through a user-friendly UI before finalizing. This human-in-the-loop design ensures that AI augments rather than replaces auditor judgment, in line with internal audit best practices.*

## Data Handling and Privacy Considerations

A key aspect of this design is that the **tool acts purely as a facilitator** – it does not retain any auditor data after the session. All risk assessment information stays in the JSON that the user and AI agent exchange, without being stored on the tool’s backend. This ephemeral handling of data is intentional to protect sensitive information (e.g. risk findings, confidential audit data). By keeping the data flow limited to the JSON passed in and out, we reduce the attack surface for data leaks or unauthorized access. It aligns with security recommendations to isolate and tightly control data used by AI tools. For instance, experts advise using strict input validation (as mentioned, via JSON schemas) and minimizing what data is persisted or logged[\[1\]](https://cyberstrategyinstitute.com/ai-safe%C2%B2-a-next-generation-secure-ai-agent-framework-for-agentic-ai-automation/#:~:text=2). In our case, **no persistent storage** means once the JSON is output back to the user/agent, the tool can discard the in-memory data. This approach reassures auditors that using the tool won’t inadvertently save their confidential risk data in some cloud or database.

Additionally, incorporating the auditor’s manual review is not just a workflow choice, but a compliance-friendly feature. Regulations and AI ethics guidelines encourage maintaining *human oversight over AI decisions*. In internal audit contexts, it’s recommended to **“ensure human oversight remains central”** and to have clear points where human judgment is applied over AI suggestions[\[5\]](https://www.wolterskluwer.com/en/expert-insights/revolutionary-impact-ai-powered-risk-assessment-internal-audit#:~:text=Implement%20a%20human). Our design implements this by requiring the auditor’s explicit confirmation and edits before finalizing risk assessment outputs. Every AI-generated recommendation is subject to human validation, and any changes are documented in the output JSON. This creates an audit trail of where the human intervened (since the differences between input and output JSON show the auditor’s modifications), which can be important for compliance and accountability.

## Benefits of the Proposed Approach

* **Simplicity for Users:** A single JSON file to represent the whole risk assessment state makes it easy for auditors to manage data. Uploading one file and downloading one file is far more user-friendly than dealing with multiple partial inputs/outputs. This simplicity is crucial if some auditors are not very technical – it reduces friction in adopting the tool.

* **Seamless AI-Tool Collaboration:** Using one JSON format ensures the AI agent and the tool speak the same language. The agent’s output can directly feed the tool and vice versa without additional conversion. It’s essentially a plug-and-play module in the AI’s workflow. In fact, this mirrors the design of official AI tool integrations, where each tool’s capabilities are exposed via a defined input/output schema that the AI can automatically utilize[\[2\]](https://zenity.io/blog/security/securing-the-model-context-protocol-mcp#:~:text=Functional%20units%20that%20the%20model,Each%20tool%20has).

* **Flexibility of Two Modes:** Supporting both an integrated mode (Flow 1\) and a manual mode (Flow 2\) covers different user scenarios. Organizations can start with the manual approach (if they haven't set up MCP integration or if auditors prefer hands-on control) and later upgrade to full AI integration without changing the underlying JSON format. Both flows yield identical results, so it’s future-proof and user-choice-friendly.

* **Maintaining Human Control:** The approach inherently implements a *human-in-the-loop* safeguard. The AI agent cannot unilaterally finalize the risk assessment – it must go through the auditor’s revisions. This addresses concerns around over-reliance on AI. Industry guidance on AI-powered auditing emphasizes that AI should assist but not replace human judgment[\[5\]](https://www.wolterskluwer.com/en/expert-insights/revolutionary-impact-ai-powered-risk-assessment-internal-audit#:~:text=Implement%20a%20human)[\[6\]](https://www.wolterskluwer.com/en/expert-insights/revolutionary-impact-ai-powered-risk-assessment-internal-audit#:~:text=match%20at%20L944%20powered%20risk,that%20neither%20could%20achieve%20alone). Our design achieves exactly that by dividing roles: AI does initial analysis, human does validation and final tweaks.

* **No Unintended Data Exposure:** By not storing data server-side, we mitigate privacy risks. Each JSON exchange is transient. This is particularly important for risk and audit data, which may be sensitive or regulated. Auditors and compliance officers can be assured that using the tool won’t accidentally leak information, as nothing persists beyond the immediate session. (Of course, standard web security still applies – using HTTPS, proper authentication if needed, etc., to protect the data in transit.)

## Conclusion

In summary, adopting a **one-JSON-in/one-JSON-out design** for the auditor’s risk assessment tool provides a clear and efficient interface between the AI agent and the human auditor. It aligns with modern AI tool integration standards (like MCP’s structured tool calls) and supports a robust human-in-the-loop process as recommended by audit industry best practices. We have outlined two usage flows: one where the AI agent connects directly to the tool to facilitate a smooth, semi-automated interaction, and another where the auditor can operate the tool manually by uploading and downloading JSON files. Both approaches ensure that the auditor has the ultimate control over the risk assessment content while leveraging the AI’s capabilities. This design choice will make it easier for auditors to collaborate with AI, improve transparency of the AI’s contributions, and maintain the necessary oversight and data security in the risk assessment workflow.

**Sources:**

* Ziv Hagbi, “Securing the Model Context Protocol (MCP): A Deep Dive into Emerging AI Risks,” *Zenity Blog*, Jun. 20, 2025\. (Describes MCP as an open standard for LLMs to interact with tools, and how tools have defined input/output schemas)[\[3\]](https://zenity.io/blog/security/securing-the-model-context-protocol-mcp#:~:text=In%202025%2C%20the%20rise%20of,tools%2C%20APIs%2C%20databases%2C%20and%20services)[\[2\]](https://zenity.io/blog/security/securing-the-model-context-protocol-mcp#:~:text=Functional%20units%20that%20the%20model,Each%20tool%20has)

* *AI-SAFE² Integrated AI Security Checklist*, Cyber Strategy Institute, 2025\. (Recommends validating JSON inputs against schemas and limiting data retention for AI tools)[\[1\]](https://cyberstrategyinstitute.com/ai-safe%C2%B2-a-next-generation-secure-ai-agent-framework-for-agentic-ai-automation/#:~:text=2)

* Wolters Kluwer TeamMate, “The Revolutionary Impact of AI-Powered Risk Assessment on Internal Audit,” Oct. 2024\. (Emphasizes human-in-the-loop best practices in AI-assisted risk assessment, ensuring human oversight and defining when humans must review AI outputs)[\[5\]](https://www.wolterskluwer.com/en/expert-insights/revolutionary-impact-ai-powered-risk-assessment-internal-audit#:~:text=Implement%20a%20human)

* Christian Posta, “Deep Dive MCP and A2A Attack Vectors for AI Agents,” *Solo.io Blog*, 2025\. (Background on MCP and Agent-to-Agent protocols, confirming JSON-RPC based tool invocation in AI agent contexts)[\[7\]](https://www.solo.io/blog/deep-dive-mcp-and-a2a-attack-vectors-for-ai-agents#:~:text=The%20Model%20Context%20Protocol%20,a%20bumpy%20ride%20so%20far)

---

[\[1\]](https://cyberstrategyinstitute.com/ai-safe%C2%B2-a-next-generation-secure-ai-agent-framework-for-agentic-ai-automation/#:~:text=2) AI SAFE²: A Next-Generation Secure AI Agent Framework for Agentic AI

[https://cyberstrategyinstitute.com/ai-safe%C2%B2-a-next-generation-secure-ai-agent-framework-for-agentic-ai-automation/](https://cyberstrategyinstitute.com/ai-safe%C2%B2-a-next-generation-secure-ai-agent-framework-for-agentic-ai-automation/)

[\[2\]](https://zenity.io/blog/security/securing-the-model-context-protocol-mcp#:~:text=Functional%20units%20that%20the%20model,Each%20tool%20has) [\[3\]](https://zenity.io/blog/security/securing-the-model-context-protocol-mcp#:~:text=In%202025%2C%20the%20rise%20of,tools%2C%20APIs%2C%20databases%2C%20and%20services) [\[4\]](https://zenity.io/blog/security/securing-the-model-context-protocol-mcp#:~:text=MCP%20is%20an%20open%2C%20composable,LLMs%29%20to) AI Agent Security | Securing the Model Context Protocol (MCP): A Deep Dive into Emerging AI Risks | Zenity

[https://zenity.io/blog/security/securing-the-model-context-protocol-mcp](https://zenity.io/blog/security/securing-the-model-context-protocol-mcp)

[\[5\]](https://www.wolterskluwer.com/en/expert-insights/revolutionary-impact-ai-powered-risk-assessment-internal-audit#:~:text=Implement%20a%20human) [\[6\]](https://www.wolterskluwer.com/en/expert-insights/revolutionary-impact-ai-powered-risk-assessment-internal-audit#:~:text=match%20at%20L944%20powered%20risk,that%20neither%20could%20achieve%20alone) AI-powered risk assessment | TeamMate | Wolters Kluwer

[https://www.wolterskluwer.com/en/expert-insights/revolutionary-impact-ai-powered-risk-assessment-internal-audit](https://www.wolterskluwer.com/en/expert-insights/revolutionary-impact-ai-powered-risk-assessment-internal-audit)

[\[7\]](https://www.solo.io/blog/deep-dive-mcp-and-a2a-attack-vectors-for-ai-agents#:~:text=The%20Model%20Context%20Protocol%20,a%20bumpy%20ride%20so%20far) Solo.io Blog | Deep Dive MCP and A2A Attack Vectors for AI Agents | Solo.io

[https://www.solo.io/blog/deep-dive-mcp-and-a2a-attack-vectors-for-ai-agents](https://www.solo.io/blog/deep-dive-mcp-and-a2a-attack-vectors-for-ai-agents)